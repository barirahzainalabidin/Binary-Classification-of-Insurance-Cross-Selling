{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%time\n\nimport pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/playground-series-s4e7/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e7/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s4e7/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:29:43.105508Z","iopub.execute_input":"2024-09-04T13:29:43.106371Z","iopub.status.idle":"2024-09-04T13:30:19.861385Z","shell.execute_reply.started":"2024-09-04T13:29:43.106310Z","shell.execute_reply":"2024-09-04T13:30:19.860419Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"CPU times: user 23.7 s, sys: 4.06 s, total: 27.8 s\nWall time: 36.7 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\ntrain.head(30)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:30:19.862912Z","iopub.execute_input":"2024-09-04T13:30:19.863228Z","iopub.status.idle":"2024-09-04T13:30:19.903900Z","shell.execute_reply.started":"2024-09-04T13:30:19.863196Z","shell.execute_reply":"2024-09-04T13:30:19.903007Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"CPU times: user 176 µs, sys: 31 µs, total: 207 µs\nWall time: 195 µs\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"    id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n0    0    Male   21                1         35.0                   0   \n1    1    Male   43                1         28.0                   0   \n2    2  Female   25                1         14.0                   1   \n3    3  Female   35                1          1.0                   0   \n4    4  Female   36                1         15.0                   1   \n5    5  Female   31                1         47.0                   1   \n6    6    Male   23                1         45.0                   1   \n7    7  Female   47                1          8.0                   0   \n8    8  Female   26                1         28.0                   1   \n9    9  Female   66                1         11.0                   0   \n10  10    Male   22                1          3.0                   1   \n11  11  Female   25                1         10.0                   0   \n12  12    Male   36                1         28.0                   0   \n13  13    Male   27                1         28.0                   1   \n14  14  Female   24                1         12.0                   1   \n15  15    Male   79                1          8.0                   0   \n16  16    Male   34                1         37.0                   0   \n17  17  Female   20                1         50.0                   1   \n18  18  Female   25                1         30.0                   1   \n19  19  Female   27                1         30.0                   1   \n20  20  Female   34                1         50.0                   1   \n21  21    Male   34                1         46.0                   1   \n22  22  Female   43                1         29.0                   1   \n23  23  Female   24                1          8.0                   0   \n24  24  Female   42                1         11.0                   0   \n25  25  Female   23                1         15.0                   0   \n26  26  Female   43                1         35.0                   1   \n27  27  Female   23                1         11.0                   1   \n28  28    Male   40                1         35.0                   0   \n29  29    Male   40                1         28.0                   0   \n\n   Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n0     1-2 Year            Yes         65101.0                 124.0      187   \n1    > 2 Years            Yes         58911.0                  26.0      288   \n2     < 1 Year             No         38043.0                 152.0      254   \n3     1-2 Year            Yes          2630.0                 156.0       76   \n4     1-2 Year             No         31951.0                 152.0      294   \n5     < 1 Year             No         28150.0                 152.0      197   \n6     < 1 Year             No         27128.0                 152.0      190   \n7     1-2 Year            Yes         40659.0                  26.0      262   \n8     < 1 Year             No         31639.0                 152.0       36   \n9     1-2 Year            Yes          2630.0                  26.0      125   \n10    < 1 Year             No         27996.0                 152.0      215   \n11    < 1 Year            Yes          2630.0                 152.0       30   \n12    1-2 Year            Yes         38104.0                  26.0      203   \n13    < 1 Year             No         43746.0                 152.0      259   \n14    < 1 Year             No         23692.0                 152.0      245   \n15   > 2 Years            Yes         66887.0                 124.0      150   \n16    1-2 Year            Yes         30226.0                  26.0      240   \n17    < 1 Year             No         36389.0                 160.0      242   \n18    < 1 Year             No         25769.0                 152.0      117   \n19    < 1 Year             No         40797.0                 152.0      151   \n20    1-2 Year             No          2630.0                   8.0      169   \n21    < 1 Year             No         29698.0                 152.0      185   \n22    1-2 Year             No         27677.0                  31.0      264   \n23    < 1 Year            Yes         33752.0                 160.0       38   \n24    1-2 Year            Yes         21473.0                  26.0      152   \n25    < 1 Year            Yes         33142.0                 152.0      151   \n26    1-2 Year             No         38089.0                 152.0      284   \n27    < 1 Year             No         28591.0                 152.0       25   \n28    1-2 Year            Yes          2630.0                 157.0      204   \n29    1-2 Year            Yes         54522.0                 124.0      181   \n\n    Response  \n0          0  \n1          1  \n2          0  \n3          0  \n4          0  \n5          0  \n6          0  \n7          1  \n8          0  \n9          0  \n10         0  \n11         0  \n12         0  \n13         0  \n14         0  \n15         0  \n16         0  \n17         0  \n18         0  \n19         0  \n20         0  \n21         0  \n22         0  \n23         0  \n24         0  \n25         0  \n26         0  \n27         0  \n28         1  \n29         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Driving_License</th>\n      <th>Region_Code</th>\n      <th>Previously_Insured</th>\n      <th>Vehicle_Age</th>\n      <th>Vehicle_Damage</th>\n      <th>Annual_Premium</th>\n      <th>Policy_Sales_Channel</th>\n      <th>Vintage</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Male</td>\n      <td>21</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>65101.0</td>\n      <td>124.0</td>\n      <td>187</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Male</td>\n      <td>43</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>&gt; 2 Years</td>\n      <td>Yes</td>\n      <td>58911.0</td>\n      <td>26.0</td>\n      <td>288</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Female</td>\n      <td>25</td>\n      <td>1</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>38043.0</td>\n      <td>152.0</td>\n      <td>254</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Female</td>\n      <td>35</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>156.0</td>\n      <td>76</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Female</td>\n      <td>36</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>31951.0</td>\n      <td>152.0</td>\n      <td>294</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Female</td>\n      <td>31</td>\n      <td>1</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>28150.0</td>\n      <td>152.0</td>\n      <td>197</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Male</td>\n      <td>23</td>\n      <td>1</td>\n      <td>45.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>27128.0</td>\n      <td>152.0</td>\n      <td>190</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Female</td>\n      <td>47</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>40659.0</td>\n      <td>26.0</td>\n      <td>262</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Female</td>\n      <td>26</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>31639.0</td>\n      <td>152.0</td>\n      <td>36</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Female</td>\n      <td>66</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>26.0</td>\n      <td>125</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>Male</td>\n      <td>22</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>27996.0</td>\n      <td>152.0</td>\n      <td>215</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>Female</td>\n      <td>25</td>\n      <td>1</td>\n      <td>10.0</td>\n      <td>0</td>\n      <td>&lt; 1 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>152.0</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>Male</td>\n      <td>36</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>38104.0</td>\n      <td>26.0</td>\n      <td>203</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>Male</td>\n      <td>27</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>43746.0</td>\n      <td>152.0</td>\n      <td>259</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>Female</td>\n      <td>24</td>\n      <td>1</td>\n      <td>12.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>23692.0</td>\n      <td>152.0</td>\n      <td>245</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>Male</td>\n      <td>79</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>0</td>\n      <td>&gt; 2 Years</td>\n      <td>Yes</td>\n      <td>66887.0</td>\n      <td>124.0</td>\n      <td>150</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>Male</td>\n      <td>34</td>\n      <td>1</td>\n      <td>37.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>30226.0</td>\n      <td>26.0</td>\n      <td>240</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>Female</td>\n      <td>20</td>\n      <td>1</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>36389.0</td>\n      <td>160.0</td>\n      <td>242</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>Female</td>\n      <td>25</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>25769.0</td>\n      <td>152.0</td>\n      <td>117</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>Female</td>\n      <td>27</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>40797.0</td>\n      <td>152.0</td>\n      <td>151</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>Female</td>\n      <td>34</td>\n      <td>1</td>\n      <td>50.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>2630.0</td>\n      <td>8.0</td>\n      <td>169</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>Male</td>\n      <td>34</td>\n      <td>1</td>\n      <td>46.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>29698.0</td>\n      <td>152.0</td>\n      <td>185</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>1</td>\n      <td>29.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>27677.0</td>\n      <td>31.0</td>\n      <td>264</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>Female</td>\n      <td>24</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>0</td>\n      <td>&lt; 1 Year</td>\n      <td>Yes</td>\n      <td>33752.0</td>\n      <td>160.0</td>\n      <td>38</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>21473.0</td>\n      <td>26.0</td>\n      <td>152</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>Female</td>\n      <td>23</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>0</td>\n      <td>&lt; 1 Year</td>\n      <td>Yes</td>\n      <td>33142.0</td>\n      <td>152.0</td>\n      <td>151</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>38089.0</td>\n      <td>152.0</td>\n      <td>284</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>Female</td>\n      <td>23</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>28591.0</td>\n      <td>152.0</td>\n      <td>25</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>Male</td>\n      <td>40</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>157.0</td>\n      <td>204</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>Male</td>\n      <td>40</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>54522.0</td>\n      <td>124.0</td>\n      <td>181</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\ntest.head(30)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:30:19.905205Z","iopub.execute_input":"2024-09-04T13:30:19.905592Z","iopub.status.idle":"2024-09-04T13:30:19.934118Z","shell.execute_reply.started":"2024-09-04T13:30:19.905548Z","shell.execute_reply":"2024-09-04T13:30:19.933361Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"CPU times: user 117 µs, sys: 20 µs, total: 137 µs\nWall time: 129 µs\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"          id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n0   11504798  Female   20                1         47.0                   0   \n1   11504799    Male   47                1         28.0                   0   \n2   11504800    Male   47                1         43.0                   0   \n3   11504801  Female   22                1         47.0                   1   \n4   11504802    Male   51                1         19.0                   0   \n5   11504803    Male   22                1         30.0                   1   \n6   11504804  Female   23                1         20.0                   0   \n7   11504805  Female   21                1         37.0                   1   \n8   11504806    Male   72                1         43.0                   1   \n9   11504807    Male   33                1         28.0                   1   \n10  11504808    Male   67                1         48.0                   0   \n11  11504809    Male   34                1         29.0                   0   \n12  11504810  Female   25                1         28.0                   1   \n13  11504811  Female   24                1         47.0                   1   \n14  11504812    Male   45                1         11.0                   1   \n15  11504813  Female   65                1         28.0                   0   \n16  11504814    Male   40                1         28.0                   1   \n17  11504815  Female   24                1         21.0                   1   \n18  11504816    Male   35                1         10.0                   1   \n19  11504817    Male   40                1          0.0                   0   \n20  11504818    Male   47                1         36.0                   0   \n21  11504819  Female   26                1         28.0                   0   \n22  11504820    Male   41                1         28.0                   0   \n23  11504821    Male   66                1         28.0                   0   \n24  11504822    Male   24                1         41.0                   1   \n25  11504823    Male   31                1         28.0                   0   \n26  11504824  Female   39                1         28.0                   1   \n27  11504825  Female   24                1         45.0                   1   \n28  11504826  Female   80                1         28.0                   0   \n29  11504827    Male   52                1         28.0                   1   \n\n   Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \n0     < 1 Year             No          2630.0                 160.0      228  \n1     1-2 Year            Yes         37483.0                 124.0      123  \n2     1-2 Year            Yes          2630.0                  26.0      271  \n3     < 1 Year             No         24502.0                 152.0      115  \n4     1-2 Year             No         34115.0                 124.0      148  \n5     < 1 Year             No         25715.0                 152.0      245  \n6     < 1 Year            Yes          2630.0                 152.0       11  \n7     < 1 Year            Yes          2630.0                 160.0      171  \n8     1-2 Year             No         38495.0                 124.0       97  \n9     < 1 Year             No         46937.0                 152.0       72  \n10    1-2 Year            Yes          2630.0                  29.0      225  \n11    < 1 Year             No          2630.0                   1.0      102  \n12    < 1 Year             No         29574.0                 152.0       36  \n13    < 1 Year             No         36601.0                 152.0      292  \n14    1-2 Year             No          2630.0                 122.0      250  \n15    1-2 Year             No          2630.0                  26.0      152  \n16    1-2 Year             No         58712.0                  26.0      278  \n17    < 1 Year             No         28963.0                 152.0       55  \n18    1-2 Year            Yes          2630.0                 156.0      193  \n19    1-2 Year             No          2630.0                  55.0      106  \n20    1-2 Year            Yes         47423.0                 124.0       73  \n21    1-2 Year            Yes          2630.0                 156.0      210  \n22    1-2 Year            Yes         33160.0                 124.0      131  \n23    1-2 Year            Yes         43573.0                  25.0       92  \n24    < 1 Year             No         40900.0                 152.0      282  \n25    < 1 Year            Yes         50579.0                 152.0      263  \n26    1-2 Year             No         46171.0                  26.0      152  \n27    < 1 Year             No         27751.0                 152.0      234  \n28    1-2 Year            Yes         49163.0                  52.0      277  \n29    1-2 Year             No         29230.0                  26.0       21  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Driving_License</th>\n      <th>Region_Code</th>\n      <th>Previously_Insured</th>\n      <th>Vehicle_Age</th>\n      <th>Vehicle_Damage</th>\n      <th>Annual_Premium</th>\n      <th>Policy_Sales_Channel</th>\n      <th>Vintage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11504798</td>\n      <td>Female</td>\n      <td>20</td>\n      <td>1</td>\n      <td>47.0</td>\n      <td>0</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>2630.0</td>\n      <td>160.0</td>\n      <td>228</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11504799</td>\n      <td>Male</td>\n      <td>47</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>37483.0</td>\n      <td>124.0</td>\n      <td>123</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11504800</td>\n      <td>Male</td>\n      <td>47</td>\n      <td>1</td>\n      <td>43.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>26.0</td>\n      <td>271</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11504801</td>\n      <td>Female</td>\n      <td>22</td>\n      <td>1</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>24502.0</td>\n      <td>152.0</td>\n      <td>115</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11504802</td>\n      <td>Male</td>\n      <td>51</td>\n      <td>1</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>34115.0</td>\n      <td>124.0</td>\n      <td>148</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>11504803</td>\n      <td>Male</td>\n      <td>22</td>\n      <td>1</td>\n      <td>30.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>25715.0</td>\n      <td>152.0</td>\n      <td>245</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>11504804</td>\n      <td>Female</td>\n      <td>23</td>\n      <td>1</td>\n      <td>20.0</td>\n      <td>0</td>\n      <td>&lt; 1 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>152.0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>11504805</td>\n      <td>Female</td>\n      <td>21</td>\n      <td>1</td>\n      <td>37.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>160.0</td>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>11504806</td>\n      <td>Male</td>\n      <td>72</td>\n      <td>1</td>\n      <td>43.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>38495.0</td>\n      <td>124.0</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>11504807</td>\n      <td>Male</td>\n      <td>33</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>46937.0</td>\n      <td>152.0</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11504808</td>\n      <td>Male</td>\n      <td>67</td>\n      <td>1</td>\n      <td>48.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>29.0</td>\n      <td>225</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11504809</td>\n      <td>Male</td>\n      <td>34</td>\n      <td>1</td>\n      <td>29.0</td>\n      <td>0</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>2630.0</td>\n      <td>1.0</td>\n      <td>102</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>11504810</td>\n      <td>Female</td>\n      <td>25</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>29574.0</td>\n      <td>152.0</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>11504811</td>\n      <td>Female</td>\n      <td>24</td>\n      <td>1</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>36601.0</td>\n      <td>152.0</td>\n      <td>292</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>11504812</td>\n      <td>Male</td>\n      <td>45</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>2630.0</td>\n      <td>122.0</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>11504813</td>\n      <td>Female</td>\n      <td>65</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>2630.0</td>\n      <td>26.0</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>11504814</td>\n      <td>Male</td>\n      <td>40</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>58712.0</td>\n      <td>26.0</td>\n      <td>278</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>11504815</td>\n      <td>Female</td>\n      <td>24</td>\n      <td>1</td>\n      <td>21.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>28963.0</td>\n      <td>152.0</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>11504816</td>\n      <td>Male</td>\n      <td>35</td>\n      <td>1</td>\n      <td>10.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>156.0</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>11504817</td>\n      <td>Male</td>\n      <td>40</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>2630.0</td>\n      <td>55.0</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>11504818</td>\n      <td>Male</td>\n      <td>47</td>\n      <td>1</td>\n      <td>36.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>47423.0</td>\n      <td>124.0</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>11504819</td>\n      <td>Female</td>\n      <td>26</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>2630.0</td>\n      <td>156.0</td>\n      <td>210</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>11504820</td>\n      <td>Male</td>\n      <td>41</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>33160.0</td>\n      <td>124.0</td>\n      <td>131</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>11504821</td>\n      <td>Male</td>\n      <td>66</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>43573.0</td>\n      <td>25.0</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>11504822</td>\n      <td>Male</td>\n      <td>24</td>\n      <td>1</td>\n      <td>41.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>40900.0</td>\n      <td>152.0</td>\n      <td>282</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>11504823</td>\n      <td>Male</td>\n      <td>31</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>&lt; 1 Year</td>\n      <td>Yes</td>\n      <td>50579.0</td>\n      <td>152.0</td>\n      <td>263</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>11504824</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>46171.0</td>\n      <td>26.0</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>11504825</td>\n      <td>Female</td>\n      <td>24</td>\n      <td>1</td>\n      <td>45.0</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>27751.0</td>\n      <td>152.0</td>\n      <td>234</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>11504826</td>\n      <td>Female</td>\n      <td>80</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>49163.0</td>\n      <td>52.0</td>\n      <td>277</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>11504827</td>\n      <td>Male</td>\n      <td>52</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>29230.0</td>\n      <td>26.0</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\n# check missing values\n\nmissing_values = train.isnull().sum()\nmissing_values","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:30:19.935965Z","iopub.execute_input":"2024-09-04T13:30:19.936254Z","iopub.status.idle":"2024-09-04T13:30:23.121292Z","shell.execute_reply.started":"2024-09-04T13:30:19.936224Z","shell.execute_reply":"2024-09-04T13:30:23.120467Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"CPU times: user 3.15 s, sys: 31.7 ms, total: 3.18 s\nWall time: 3.18 s\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"id                      0\nGender                  0\nAge                     0\nDriving_License         0\nRegion_Code             0\nPreviously_Insured      0\nVehicle_Age             0\nVehicle_Damage          0\nAnnual_Premium          0\nPolicy_Sales_Channel    0\nVintage                 0\nResponse                0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Use h2o automl to train model","metadata":{}},{"cell_type":"markdown","source":"* I used h2o automl to handle training large dataset . ","metadata":{}},{"cell_type":"code","source":"%%time\n\nimport h2o\nprint(h2o.__version__)\nfrom h2o.automl import H2OAutoML\n\nh2o.init(max_mem_size='16G')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:30:23.122274Z","iopub.execute_input":"2024-09-04T13:30:23.122538Z","iopub.status.idle":"2024-09-04T13:30:30.835053Z","shell.execute_reply.started":"2024-09-04T13:30:23.122509Z","shell.execute_reply":"2024-09-04T13:30:30.834089Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"3.46.0.4\nChecking whether there is an H2O instance running at http://localhost:54321..... not found.\nAttempting to start a local H2O server...\n  Java Version: openjdk version \"11.0.24\" 2024-07-16; OpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu322.04); OpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu322.04, mixed mode, sharing)\n  Starting server from /opt/conda/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n  Ice root: /tmp/tmpsn7m4bpx\n  JVM stdout: /tmp/tmpsn7m4bpx/h2o_unknownUser_started_from_python.out\n  JVM stderr: /tmp/tmpsn7m4bpx/h2o_unknownUser_started_from_python.err\n  Server is running at http://127.0.0.1:54321\nConnecting to H2O server at http://127.0.0.1:54321 ... successful.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"--------------------------  ----------------------------------\nH2O_cluster_uptime:         02 secs\nH2O_cluster_timezone:       Etc/UTC\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.46.0.4\nH2O_cluster_version_age:    1 month and 25 days\nH2O_cluster_name:           H2O_from_python_unknownUser_xyh3df\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    16 Gb\nH2O_cluster_total_cores:    4\nH2O_cluster_allowed_cores:  4\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.10.14 final\n--------------------------  ----------------------------------","text/html":"\n<style>\n\n#h2o-table-1.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-1 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-1 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-1 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-1 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-1 .h2o-table th,\n#h2o-table-1 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-1 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-1\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>02 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.46.0.4</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>1 month and 25 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_unknownUser_xyh3df</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>16 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.10.14 final</td></tr></tbody>\n  </table>\n</div>\n"},"metadata":{}},{"name":"stdout","text":"CPU times: user 314 ms, sys: 79.3 ms, total: 394 ms\nWall time: 7.71 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\ntrain = h2o.import_file(\"/kaggle/input/playground-series-s4e7/train.csv\")\ntest = h2o.import_file(\"/kaggle/input/playground-series-s4e7/test.csv\")\nsample_submission = h2o.import_file(\"/kaggle/input/playground-series-s4e7/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:30:30.836604Z","iopub.execute_input":"2024-09-04T13:30:30.837582Z","iopub.status.idle":"2024-09-04T13:30:56.629859Z","shell.execute_reply.started":"2024-09-04T13:30:30.837533Z","shell.execute_reply":"2024-09-04T13:30:56.628763Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\nParse progress: |████████████████████████████████████████████████████████████████| (done) 100%\nParse progress: |████████████████████████████████████████████████████████████████| (done) 100%\nCPU times: user 584 ms, sys: 76.1 ms, total: 660 ms\nWall time: 25.8 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\nx = train.columns[1:]\ny = 'Response'","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:30:56.631592Z","iopub.execute_input":"2024-09-04T13:30:56.632242Z","iopub.status.idle":"2024-09-04T13:30:56.638019Z","shell.execute_reply.started":"2024-09-04T13:30:56.632193Z","shell.execute_reply":"2024-09-04T13:30:56.636935Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"CPU times: user 18 µs, sys: 0 ns, total: 18 µs\nWall time: 22.4 µs\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:30:56.639292Z","iopub.execute_input":"2024-09-04T13:30:56.639693Z","iopub.status.idle":"2024-09-04T13:30:56.649635Z","shell.execute_reply.started":"2024-09-04T13:30:56.639651Z","shell.execute_reply":"2024-09-04T13:30:56.648734Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"CPU times: user 239 µs, sys: 28 µs, total: 267 µs\nWall time: 270 µs\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\naml = H2OAutoML(max_models=200, seed=1000, max_runtime_secs=1000)\naml.train(x=x, y=y, training_frame=train)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:30:56.650869Z","iopub.execute_input":"2024-09-04T13:30:56.651170Z","iopub.status.idle":"2024-09-04T13:47:55.329320Z","shell.execute_reply.started":"2024-09-04T13:30:56.651140Z","shell.execute_reply":"2024-09-04T13:47:55.325587Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\nCPU times: user 6.84 s, sys: 675 ms, total: 7.52 s\nWall time: 16min 58s\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: GBM_1_AutoML_1_20240904_133057\n\n\nModel Summary: \n    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n    75                 75                          2.99006e+06            0            15           10.0667       1             6969          3173.79\n\nModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 0.0812963545001875\nRMSE: 0.2851251558529824\nLogLoss: 0.24867423214366913\nMean Per-Class Error: 0.22347833731764127\nAUC: 0.8849346271919885\nAUCPR: 0.4596376811415074\nGini: 0.7698692543839769\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.2574963709529308\n       0            1            Error    Rate\n-----  -----------  -----------  -------  ---------------------\n0      5.92879e+06  1.13237e+06  0.1604   (1132370.0/7061162.0)\n1      283740       706313       0.2866   (283740.0/990053.0)\nTotal  6.21253e+06  1.83868e+06  0.1759   (1416110.0/8051215.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value        idx\n---------------------------  -----------  -----------  -----\nmax f1                       0.257496     0.499384     206\nmax f2                       0.152106     0.661862     283\nmax f0point5                 0.351828     0.459149     135\nmax accuracy                 0.454005     0.882287     74\nmax precision                0.792977     0.942857     0\nmax recall                   0.00113261   1            399\nmax specificity              0.792977     1            0\nmax absolute_mcc             0.203929     0.440995     247\nmax min_per_class_accuracy   0.221509     0.798175     234\nmax mean_per_class_accuracy  0.141799     0.817692     290\nmax tns                      0.792977     7.06116e+06  0\nmax fns                      0.792977     990020       0\nmax fps                      0.00113261   7.06116e+06  399\nmax tps                      0.00113261   990053       399\nmax tnr                      0.792977     1            0\nmax fnr                      0.792977     0.999967     0\nmax fpr                      0.00113261   1            399\nmax tpr                      0.00113261   1            399\n\nGains/Lift Table: Avg response rate: 12.30 %, avg score: 12.31 %\ngroup    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  -----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.0100001                   0.526025           5.42177      5.42177            0.666712         0.571785    0.666712                    0.571785            0.0542183       0.0542183                  442.177   442.177            0.0504181\n2        0.0200001                   0.484513           4.63724      5.02951            0.570238         0.503233    0.618475                    0.53751             0.0463723       0.100591                   363.724   402.951            0.0918902\n3        0.0300001                   0.458211           4.27049      4.7765             0.525139         0.470713    0.587363                    0.515244            0.0427048       0.143295                   327.049   377.65             0.129181\n4        0.04                        0.438073           4.02494      4.58861            0.494945         0.44767     0.564259                    0.498351            0.0402494       0.183545                   302.494   358.861            0.163671\n5        0.05                        0.421568           3.8192       4.43473            0.469644         0.429622    0.545336                    0.484605            0.0381919       0.221737                   281.92    343.473            0.195816\n6        0.1                         0.361084           3.36374      3.89923            0.413637         0.389014    0.479486                    0.436809            0.168187        0.389924                   236.374   289.923            0.330574\n7        0.15                        0.317344           2.84267      3.54705            0.349562         0.338511    0.436178                    0.404043            0.142134        0.532057                   184.267   254.705            0.435626\n8        0.2                         0.278596           2.41658      3.26443            0.297166         0.297811    0.401425                    0.377485            0.120829        0.652886                   141.658   226.443            0.516386\n9        0.3                         0.201161           1.86719      2.79868            0.229607         0.24047     0.344153                    0.331813            0.186719        0.839606                   86.7192   179.868            0.615264\n10       0.4                         0.109901           1.13941      2.38387            0.140113         0.156771    0.293143                    0.288053            0.113941        0.953547                   13.9412   138.387            0.63116\n11       0.5                         0.0258318          0.428665     1.99283            0.0527126        0.0649089   0.245057                    0.243424            0.0428664       0.996413                   -57.1335  99.2826            0.566016\n12       0.6                         0.00176178         0.0329376    1.66618            0.00405032       0.00893751  0.204889                    0.204343            0.00329376      0.999707                   -96.7062  66.6178            0.45575\n13       0.7                         0.00134526         0.00108075   1.42831            0.000132899      0.00156384  0.175638                    0.175374            0.000108075     0.999815                   -99.8919  42.8307            0.341852\n14       0.8                         0.00116667         0.00125246   1.24993            0.000154014      0.00122165  0.153703                    0.153605            0.000125246     0.99994                    -99.8748  24.9925            0.227974\n15       0.900006                    0.00111925         0.000484792  1.11109            5.96146e-05      0.00114568  0.13663                     0.136664            4.84823e-05     0.999989                   -99.9515  11.1091            0.114001\n16       1                           0.000851075        0.000111112  1                  1.36634e-05      0.00108987  0.122969                    0.123108            1.11105e-05     1                          -99.9889  0                  0\n\nModelMetricsBinomial: gbm\n** Reported on validation data. **\n\nMSE: 0.08255829622091279\nRMSE: 0.28732959510101425\nLogLoss: 0.2531580092731151\nMean Per-Class Error: 0.2345624532060706\nAUC: 0.8782703164986668\nAUCPR: 0.4383434663181883\nGini: 0.7565406329973337\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.26080699595275686\n       0       1       Error    Rate\n-----  ------  ------  -------  --------------------\n0      849774  160729  0.1591   (160729.0/1010503.0)\n1      43831   97529   0.3101   (43831.0/141360.0)\nTotal  893605  258258  0.1776   (204560.0/1151863.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value       idx\n---------------------------  -----------  ----------  -----\nmax f1                       0.260807     0.488111    203\nmax f2                       0.132104     0.653139    295\nmax f0point5                 0.354927     0.445327    136\nmax accuracy                 0.469323     0.880836    70\nmax precision                0.786284     1           0\nmax recall                   0.00113895   1           399\nmax specificity              0.786284     1           0\nmax absolute_mcc             0.191212     0.428444    255\nmax min_per_class_accuracy   0.218027     0.791826    235\nmax mean_per_class_accuracy  0.132104     0.81168     295\nmax tns                      0.786284     1.0105e+06  0\nmax fns                      0.786284     141355      0\nmax fps                      0.00113895   1.0105e+06  399\nmax tps                      0.00113895   141360      399\nmax tnr                      0.786284     1           0\nmax fnr                      0.786284     0.999965    0\nmax fpr                      0.00113895   1           399\nmax tpr                      0.00113895   1           399\n\nGains/Lift Table: Avg response rate: 12.27 %, avg score: 12.31 %\ngroup    cumulative_data_fraction    lower_threshold    lift         cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  -----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.0100003                   0.525605           5.09392      5.09392            0.625141         0.570784    0.625141                    0.570784            0.0509409       0.0509409                  409.392   409.392            0.0466677\n2        0.0200006                   0.484589           4.4028       4.74836            0.540325         0.502939    0.582733                    0.536862            0.0440294       0.0949703                  340.28    374.836            0.0854572\n3        0.0300001                   0.458103           4.14567      4.54748            0.508769         0.470619    0.55808                     0.514782            0.0414544       0.136425                   314.567   354.748            0.121312\n4        0.0400004                   0.437705           3.89277      4.3838             0.477732         0.447397    0.537992                    0.497935            0.038929        0.175354                   289.277   338.38             0.154288\n5        0.0500007                   0.421326           3.71522      4.25008            0.455942         0.429355    0.521582                    0.484219            0.0371534       0.212507                   271.522   325.008            0.185239\n6        0.100001                    0.360944           3.3049       3.7775             0.405587         0.388854    0.463585                    0.436537            0.165245        0.377752                   230.49    277.75             0.316606\n7        0.15                        0.317529           2.80519      3.45339            0.344261         0.338528    0.423811                    0.403867            0.140259        0.518011                   180.519   245.339            0.419492\n8        0.2                         0.278608           2.40182      3.1905             0.294758         0.297959    0.391548                    0.37739             0.120091        0.638101                   140.182   219.05             0.499387\n9        0.3                         0.200985           1.86178      2.74759            0.228483         0.240352    0.337193                    0.331711            0.186177        0.824278                   86.1776   174.759            0.59762\n10       0.4                         0.110221           1.20671      2.36237            0.148091         0.15678     0.289917                    0.287978            0.120671        0.944949                   20.6709   136.237            0.621183\n11       0.5                         0.0262363          0.481887     1.98627            0.0591386        0.0652859   0.243761                    0.24344             0.048189        0.993138                   -51.8113  98.6274            0.562123\n12       0.6                         0.00176708         0.0617574    1.66552            0.00757905       0.00907328  0.204398                    0.204379            0.00617572      0.999314                   -93.8243  66.5523            0.455174\n13       0.7                         0.00134747         0.00339559   1.42808            0.000416717      0.00156679  0.175258                    0.175406            0.000339559     0.999653                   -99.6604  42.8076            0.341572\n14       0.800001                    0.00116674         0.00162704   1.24977            0.000199675      0.00122196  0.153375                    0.153633            0.000162705     0.999816                   -99.8373  24.9769            0.227768\n15       0.900001                    0.00111933         0.0015563    1.11108            0.000190994      0.00114579  0.136355                    0.13669             0.000155631     0.999972                   -99.8444  11.1078            0.113956\n16       1                           0.00086545         0.000282969  1                  3.47267e-05      0.00109013  0.122723                    0.12313             2.82965e-05     1                          -99.9717  0                  0\n\nScoring History: \n    timestamp            duration          number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n--  -------------------  ----------------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n    2024-09-04 13:39:26  0.303 sec         0                  0.328402         0.3728              0.5             0.122969           1                0.877031                         0.328119           0.372316              0.5               0.122723             1                  0.877277\n    2024-09-04 13:40:05  40.102 sec        5                  0.305014         0.309736            0.87327         0.422011           4.85926          0.190872                         0.305145           0.310208              0.870134          0.412095             4.68576            0.192469\n    2024-09-04 13:40:43  1 min 17.748 sec  10                 0.295611         0.284749            0.875004        0.426037           4.91637          0.192888                         0.296108           0.285877              0.871523          0.414366             4.68505            0.196114\n    2024-09-04 13:41:19  1 min 54.142 sec  15                 0.291346         0.270901            0.876513        0.430498           4.95508          0.188593                         0.292147           0.272555              0.872617          0.417244             4.73103            0.192927\n    2024-09-04 13:41:59  2 min 33.389 sec  20                 0.289375         0.263494            0.877631        0.433797           5.01089          0.187789                         0.290527           0.265779              0.873058          0.418183             4.76994            0.195796\n    2024-09-04 13:42:34  3 min  8.663 sec  25                 0.287975         0.25807             0.879423        0.440801           5.13775          0.183851                         0.289349           0.260782              0.874497          0.424302             4.86331            0.185641\n    2024-09-04 13:43:12  3 min 46.355 sec  30                 0.287032         0.25461             0.881129        0.446761           5.22795          0.18073                          0.288706           0.25791               0.875519          0.427948             4.91778            0.180221\n    2024-09-04 13:43:48  4 min 22.443 sec  35                 0.286184         0.251898            0.882741        0.452211           5.31461          0.18011                          0.28805            0.255637              0.876779          0.43283              4.99206            0.178959\n    2024-09-04 13:44:22  4 min 56.367 sec  40                 0.285572         0.250135            0.884055        0.456646           5.38127          0.176216                         0.28762            0.254253              0.877707          0.436244             5.05643            0.181782\n    2024-09-04 13:44:50  5 min 24.470 sec  45                 0.285454         0.249495            0.884268        0.457256           5.38824          0.176075                         0.287555           0.253761              0.877817          0.436558             5.05741            0.182463\n    2024-09-04 13:45:11  5 min 45.752 sec  50                 0.28537          0.249198            0.88443         0.457805           5.39713          0.175027                         0.287511           0.253552              0.877903          0.436846             5.05006            0.179472\n    2024-09-04 13:45:34  6 min  8.853 sec  55                 0.285125         0.248674            0.884935        0.459638           5.42177          0.175888                         0.28733            0.253158              0.87827           0.438343             5.09392            0.177591\n    2024-09-04 13:45:46  6 min 21.210 sec  60                 0.285125         0.248674            0.884935        0.459638           5.42177          0.175888                         0.28733            0.253158              0.87827           0.438343             5.09392            0.177591\n    2024-09-04 13:45:59  6 min 33.696 sec  65                 0.285125         0.248674            0.884935        0.459638           5.42177          0.175888                         0.28733            0.253158              0.87827           0.438343             5.09392            0.177591\n    2024-09-04 13:46:11  6 min 45.923 sec  70                 0.285125         0.248674            0.884935        0.459638           5.42177          0.175888                         0.28733            0.253158              0.87827           0.438343             5.09392            0.177591\n    2024-09-04 13:46:24  6 min 58.661 sec  75                 0.285125         0.248674            0.884935        0.459638           5.42177          0.175888                         0.28733            0.253158              0.87827           0.438343             5.09392            0.177591\n\nVariable Importances: \nvariable              relative_importance    scaled_importance    percentage\n--------------------  ---------------------  -------------------  ------------\nVehicle_Damage        387860                 1                    0.401849\nPreviously_Insured    150472                 0.387955             0.155899\nAge                   145689                 0.375623             0.150944\nVintage               91172.5                0.235066             0.0944608\nVehicle_Age           71112.4                0.183345             0.0736772\nPolicy_Sales_Channel  59822.2                0.154237             0.0619798\nRegion_Code           29632.6                0.0764003            0.0307014\nAnnual_Premium        25456.5                0.0656331            0.0263746\nGender                3455.32                0.00890867           0.00357994\nDriving_License       516.366                0.00133132           0.000534989\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.","text/html":"<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: GBM_1_AutoML_1_20240904_133057\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-2.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-2 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-2 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-2 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-2 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-2 .h2o-table th,\n#h2o-table-2 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-2 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-2\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Model Summary: </caption>\n    <thead><tr><th></th>\n<th>number_of_trees</th>\n<th>number_of_internal_trees</th>\n<th>model_size_in_bytes</th>\n<th>min_depth</th>\n<th>max_depth</th>\n<th>mean_depth</th>\n<th>min_leaves</th>\n<th>max_leaves</th>\n<th>mean_leaves</th></tr></thead>\n    <tbody><tr><td></td>\n<td>75.0</td>\n<td>75.0</td>\n<td>2990064.0</td>\n<td>0.0</td>\n<td>15.0</td>\n<td>10.066667</td>\n<td>1.0</td>\n<td>6969.0</td>\n<td>3173.7866</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 0.0812963545001875\nRMSE: 0.2851251558529824\nLogLoss: 0.24867423214366913\nMean Per-Class Error: 0.22347833731764127\nAUC: 0.8849346271919885\nAUCPR: 0.4596376811415074\nGini: 0.7698692543839769</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-3.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-3 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-3 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-3 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-3 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-3 .h2o-table th,\n#h2o-table-3 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-3 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-3\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2574963709529308</caption>\n    <thead><tr><th></th>\n<th>0</th>\n<th>1</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>0</td>\n<td>5928792.0</td>\n<td>1132370.0</td>\n<td>0.1604</td>\n<td> (1132370.0/7061162.0)</td></tr>\n<tr><td>1</td>\n<td>283740.0</td>\n<td>706313.0</td>\n<td>0.2866</td>\n<td> (283740.0/990053.0)</td></tr>\n<tr><td>Total</td>\n<td>6212532.0</td>\n<td>1838683.0</td>\n<td>0.1759</td>\n<td> (1416110.0/8051215.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-4.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-4 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-4 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-4 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-4 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-4 .h2o-table th,\n#h2o-table-4 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-4 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-4\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.2574964</td>\n<td>0.4993842</td>\n<td>206.0</td></tr>\n<tr><td>max f2</td>\n<td>0.1521064</td>\n<td>0.6618624</td>\n<td>283.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.3518285</td>\n<td>0.4591491</td>\n<td>135.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.4540050</td>\n<td>0.8822871</td>\n<td>74.0</td></tr>\n<tr><td>max precision</td>\n<td>0.7929774</td>\n<td>0.9428571</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.0011326</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.7929774</td>\n<td>0.9999997</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.2039288</td>\n<td>0.4409951</td>\n<td>247.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.2215090</td>\n<td>0.7981753</td>\n<td>234.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.1417994</td>\n<td>0.8176925</td>\n<td>290.0</td></tr>\n<tr><td>max tns</td>\n<td>0.7929774</td>\n<td>7061160.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.7929774</td>\n<td>990020.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0011326</td>\n<td>7061162.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.0011326</td>\n<td>990053.0</td>\n<td>399.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.7929774</td>\n<td>0.9999997</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.7929774</td>\n<td>0.9999667</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0011326</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.0011326</td>\n<td>1.0</td>\n<td>399.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-5.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-5 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-5 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-5 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-5 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-5 .h2o-table th,\n#h2o-table-5 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-5 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-5\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 12.30 %, avg score: 12.31 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0100001</td>\n<td>0.5260249</td>\n<td>5.4217737</td>\n<td>5.4217737</td>\n<td>0.6667122</td>\n<td>0.5717853</td>\n<td>0.6667122</td>\n<td>0.5717853</td>\n<td>0.0542183</td>\n<td>0.0542183</td>\n<td>442.1773713</td>\n<td>442.1773713</td>\n<td>0.0504181</td></tr>\n<tr><td>2</td>\n<td>0.0200001</td>\n<td>0.4845126</td>\n<td>4.6372351</td>\n<td>5.0295069</td>\n<td>0.5702380</td>\n<td>0.5032332</td>\n<td>0.6184754</td>\n<td>0.5375095</td>\n<td>0.0463723</td>\n<td>0.1005906</td>\n<td>363.7235131</td>\n<td>402.9506858</td>\n<td>0.0918902</td></tr>\n<tr><td>3</td>\n<td>0.0300001</td>\n<td>0.4582111</td>\n<td>4.2704864</td>\n<td>4.7765011</td>\n<td>0.5251391</td>\n<td>0.4707125</td>\n<td>0.5873634</td>\n<td>0.5152439</td>\n<td>0.0427048</td>\n<td>0.1432954</td>\n<td>327.0486405</td>\n<td>377.6501088</td>\n<td>0.1291805</td></tr>\n<tr><td>4</td>\n<td>0.0400000</td>\n<td>0.4380731</td>\n<td>4.0249435</td>\n<td>4.5886123</td>\n<td>0.4949449</td>\n<td>0.4476701</td>\n<td>0.5642589</td>\n<td>0.4983505</td>\n<td>0.0402494</td>\n<td>0.1835447</td>\n<td>302.4943538</td>\n<td>358.8612284</td>\n<td>0.1636712</td></tr>\n<tr><td>5</td>\n<td>0.0500000</td>\n<td>0.4215676</td>\n<td>3.8191966</td>\n<td>4.4347295</td>\n<td>0.4696443</td>\n<td>0.4296220</td>\n<td>0.5453360</td>\n<td>0.4846048</td>\n<td>0.0381919</td>\n<td>0.2217366</td>\n<td>281.9196593</td>\n<td>343.4729528</td>\n<td>0.1958160</td></tr>\n<tr><td>6</td>\n<td>0.1000001</td>\n<td>0.3610841</td>\n<td>3.3637370</td>\n<td>3.8992333</td>\n<td>0.4136367</td>\n<td>0.3890138</td>\n<td>0.4794863</td>\n<td>0.4368093</td>\n<td>0.1681870</td>\n<td>0.3899236</td>\n<td>236.3737024</td>\n<td>289.9233276</td>\n<td>0.3305740</td></tr>\n<tr><td>7</td>\n<td>0.1500001</td>\n<td>0.3173441</td>\n<td>2.8426743</td>\n<td>3.5470470</td>\n<td>0.3495619</td>\n<td>0.3385107</td>\n<td>0.4361782</td>\n<td>0.4040431</td>\n<td>0.1421338</td>\n<td>0.5320574</td>\n<td>184.2674334</td>\n<td>254.7046962</td>\n<td>0.4356259</td></tr>\n<tr><td>8</td>\n<td>0.2</td>\n<td>0.2785959</td>\n<td>2.4165822</td>\n<td>3.2644313</td>\n<td>0.2971656</td>\n<td>0.2978105</td>\n<td>0.4014251</td>\n<td>0.3774850</td>\n<td>0.1208289</td>\n<td>0.6528863</td>\n<td>141.6582201</td>\n<td>226.4431298</td>\n<td>0.5163859</td></tr>\n<tr><td>9</td>\n<td>0.3000001</td>\n<td>0.2011614</td>\n<td>1.8671918</td>\n<td>2.7986846</td>\n<td>0.2296074</td>\n<td>0.2404700</td>\n<td>0.3441525</td>\n<td>0.3318133</td>\n<td>0.1867193</td>\n<td>0.8396056</td>\n<td>86.7191809</td>\n<td>179.8684609</td>\n<td>0.6152642</td></tr>\n<tr><td>10</td>\n<td>0.4000002</td>\n<td>0.1099006</td>\n<td>1.1394116</td>\n<td>2.3838658</td>\n<td>0.1401128</td>\n<td>0.1567706</td>\n<td>0.2931425</td>\n<td>0.2880526</td>\n<td>0.1139414</td>\n<td>0.9535469</td>\n<td>13.9411626</td>\n<td>138.3865848</td>\n<td>0.6311600</td></tr>\n<tr><td>11</td>\n<td>0.5000001</td>\n<td>0.0258318</td>\n<td>0.4286647</td>\n<td>1.9928264</td>\n<td>0.0527126</td>\n<td>0.0649089</td>\n<td>0.2450566</td>\n<td>0.2434239</td>\n<td>0.0428664</td>\n<td>0.9964133</td>\n<td>-57.1335281</td>\n<td>99.2826399</td>\n<td>0.5660159</td></tr>\n<tr><td>12</td>\n<td>0.6000001</td>\n<td>0.0017618</td>\n<td>0.0329376</td>\n<td>1.6661781</td>\n<td>0.0040503</td>\n<td>0.0089375</td>\n<td>0.2048889</td>\n<td>0.2043428</td>\n<td>0.0032938</td>\n<td>0.9997071</td>\n<td>-96.7062390</td>\n<td>66.6178132</td>\n<td>0.4557503</td></tr>\n<tr><td>13</td>\n<td>0.7000001</td>\n<td>0.0013453</td>\n<td>0.0010808</td>\n<td>1.4283072</td>\n<td>0.0001329</td>\n<td>0.0015638</td>\n<td>0.1756381</td>\n<td>0.1753744</td>\n<td>0.0001081</td>\n<td>0.9998152</td>\n<td>-99.8919249</td>\n<td>42.8307247</td>\n<td>0.3418525</td></tr>\n<tr><td>14</td>\n<td>0.8000001</td>\n<td>0.0011667</td>\n<td>0.0012525</td>\n<td>1.2499253</td>\n<td>0.0001540</td>\n<td>0.0012216</td>\n<td>0.1537026</td>\n<td>0.1536053</td>\n<td>0.0001252</td>\n<td>0.9999404</td>\n<td>-99.8747543</td>\n<td>24.9925315</td>\n<td>0.2279741</td></tr>\n<tr><td>15</td>\n<td>0.9000064</td>\n<td>0.0011192</td>\n<td>0.0004848</td>\n<td>1.1110909</td>\n<td>0.0000596</td>\n<td>0.0011457</td>\n<td>0.1366302</td>\n<td>0.1366644</td>\n<td>0.0000485</td>\n<td>0.9999889</td>\n<td>-99.9515208</td>\n<td>11.1090869</td>\n<td>0.1140011</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.0008511</td>\n<td>0.0001111</td>\n<td>1.0</td>\n<td>0.0000137</td>\n<td>0.0010899</td>\n<td>0.1229694</td>\n<td>0.1231078</td>\n<td>0.0000111</td>\n<td>1.0</td>\n<td>-99.9888888</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on validation data. **\n\nMSE: 0.08255829622091279\nRMSE: 0.28732959510101425\nLogLoss: 0.2531580092731151\nMean Per-Class Error: 0.2345624532060706\nAUC: 0.8782703164986668\nAUCPR: 0.4383434663181883\nGini: 0.7565406329973337</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-6.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-6 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-6 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-6 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-6 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-6 .h2o-table th,\n#h2o-table-6 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-6 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-6\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.26080699595275686</caption>\n    <thead><tr><th></th>\n<th>0</th>\n<th>1</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>0</td>\n<td>849774.0</td>\n<td>160729.0</td>\n<td>0.1591</td>\n<td> (160729.0/1010503.0)</td></tr>\n<tr><td>1</td>\n<td>43831.0</td>\n<td>97529.0</td>\n<td>0.3101</td>\n<td> (43831.0/141360.0)</td></tr>\n<tr><td>Total</td>\n<td>893605.0</td>\n<td>258258.0</td>\n<td>0.1776</td>\n<td> (204560.0/1151863.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-7.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-7 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-7 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-7 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-7 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-7 .h2o-table th,\n#h2o-table-7 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-7 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-7\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.2608070</td>\n<td>0.4881111</td>\n<td>203.0</td></tr>\n<tr><td>max f2</td>\n<td>0.1321042</td>\n<td>0.6531390</td>\n<td>295.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.3549269</td>\n<td>0.4453270</td>\n<td>136.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.4693234</td>\n<td>0.8808357</td>\n<td>70.0</td></tr>\n<tr><td>max precision</td>\n<td>0.7862842</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.0011390</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.7862842</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.1912117</td>\n<td>0.4284440</td>\n<td>255.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.2180265</td>\n<td>0.7918264</td>\n<td>235.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.1321042</td>\n<td>0.8116802</td>\n<td>295.0</td></tr>\n<tr><td>max tns</td>\n<td>0.7862842</td>\n<td>1010503.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.7862842</td>\n<td>141355.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0011390</td>\n<td>1010503.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.0011390</td>\n<td>141360.0</td>\n<td>399.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.7862842</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.7862842</td>\n<td>0.9999646</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0011390</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.0011390</td>\n<td>1.0</td>\n<td>399.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-8.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-8 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-8 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-8 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-8 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-8 .h2o-table th,\n#h2o-table-8 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-8 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-8\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 12.27 %, avg score: 12.31 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0100003</td>\n<td>0.5256049</td>\n<td>5.0939224</td>\n<td>5.0939224</td>\n<td>0.6251411</td>\n<td>0.5707841</td>\n<td>0.6251411</td>\n<td>0.5707841</td>\n<td>0.0509409</td>\n<td>0.0509409</td>\n<td>409.3922395</td>\n<td>409.3922395</td>\n<td>0.0466677</td></tr>\n<tr><td>2</td>\n<td>0.0200006</td>\n<td>0.4845893</td>\n<td>4.4028014</td>\n<td>4.7483619</td>\n<td>0.5403247</td>\n<td>0.5029393</td>\n<td>0.5827329</td>\n<td>0.5368617</td>\n<td>0.0440294</td>\n<td>0.0949703</td>\n<td>340.2801415</td>\n<td>374.8361905</td>\n<td>0.0854572</td></tr>\n<tr><td>3</td>\n<td>0.0300001</td>\n<td>0.4581029</td>\n<td>4.1456710</td>\n<td>4.5474766</td>\n<td>0.5087689</td>\n<td>0.4706188</td>\n<td>0.5580796</td>\n<td>0.5147820</td>\n<td>0.0414544</td>\n<td>0.1364247</td>\n<td>314.5670999</td>\n<td>354.7476564</td>\n<td>0.1213125</td></tr>\n<tr><td>4</td>\n<td>0.0400004</td>\n<td>0.4377047</td>\n<td>3.8927725</td>\n<td>4.3837970</td>\n<td>0.4777324</td>\n<td>0.4473971</td>\n<td>0.5379924</td>\n<td>0.4979354</td>\n<td>0.0389290</td>\n<td>0.1753537</td>\n<td>289.2772523</td>\n<td>338.3797001</td>\n<td>0.1542880</td></tr>\n<tr><td>5</td>\n<td>0.0500007</td>\n<td>0.4213259</td>\n<td>3.7152174</td>\n<td>4.2500788</td>\n<td>0.4559424</td>\n<td>0.4293551</td>\n<td>0.5215821</td>\n<td>0.4842191</td>\n<td>0.0371534</td>\n<td>0.2125071</td>\n<td>271.5217389</td>\n<td>325.0078757</td>\n<td>0.1852395</td></tr>\n<tr><td>6</td>\n<td>0.1000006</td>\n<td>0.3609443</td>\n<td>3.3049039</td>\n<td>3.7774954</td>\n<td>0.4055875</td>\n<td>0.3888537</td>\n<td>0.4635853</td>\n<td>0.4365368</td>\n<td>0.1652448</td>\n<td>0.3777518</td>\n<td>230.4903910</td>\n<td>277.7495436</td>\n<td>0.3166061</td></tr>\n<tr><td>7</td>\n<td>0.1500005</td>\n<td>0.3175295</td>\n<td>2.8051856</td>\n<td>3.4533940</td>\n<td>0.3442606</td>\n<td>0.3385278</td>\n<td>0.4238106</td>\n<td>0.4038674</td>\n<td>0.1402589</td>\n<td>0.5180108</td>\n<td>180.5185574</td>\n<td>245.3394025</td>\n<td>0.4194915</td></tr>\n<tr><td>8</td>\n<td>0.2000003</td>\n<td>0.2786075</td>\n<td>2.4018172</td>\n<td>3.1905010</td>\n<td>0.2947580</td>\n<td>0.2979588</td>\n<td>0.3915476</td>\n<td>0.3773903</td>\n<td>0.1200905</td>\n<td>0.6381013</td>\n<td>140.1817235</td>\n<td>219.0500968</td>\n<td>0.4993872</td></tr>\n<tr><td>9</td>\n<td>0.3000001</td>\n<td>0.2009852</td>\n<td>1.8617762</td>\n<td>2.7475940</td>\n<td>0.2284826</td>\n<td>0.2403518</td>\n<td>0.3371928</td>\n<td>0.3317110</td>\n<td>0.1861771</td>\n<td>0.8242784</td>\n<td>86.1776213</td>\n<td>174.7593998</td>\n<td>0.5976200</td></tr>\n<tr><td>10</td>\n<td>0.3999998</td>\n<td>0.1102210</td>\n<td>1.2067094</td>\n<td>2.3623737</td>\n<td>0.1480909</td>\n<td>0.1567804</td>\n<td>0.2899174</td>\n<td>0.2879784</td>\n<td>0.1206706</td>\n<td>0.9449491</td>\n<td>20.6709425</td>\n<td>136.2373691</td>\n<td>0.6211826</td></tr>\n<tr><td>11</td>\n<td>0.5000004</td>\n<td>0.0262363</td>\n<td>0.4818873</td>\n<td>1.9862744</td>\n<td>0.0591386</td>\n<td>0.0652859</td>\n<td>0.2437614</td>\n<td>0.2434397</td>\n<td>0.0481890</td>\n<td>0.9931381</td>\n<td>-51.8112719</td>\n<td>98.6274450</td>\n<td>0.5621230</td></tr>\n<tr><td>12</td>\n<td>0.6000002</td>\n<td>0.0017671</td>\n<td>0.0617574</td>\n<td>1.6655225</td>\n<td>0.0075790</td>\n<td>0.0090733</td>\n<td>0.2043978</td>\n<td>0.2043787</td>\n<td>0.0061757</td>\n<td>0.9993138</td>\n<td>-93.8242624</td>\n<td>66.5522533</td>\n<td>0.4551739</td></tr>\n<tr><td>13</td>\n<td>0.6999999</td>\n<td>0.0013475</td>\n<td>0.0033956</td>\n<td>1.4280764</td>\n<td>0.0004167</td>\n<td>0.0015668</td>\n<td>0.1752577</td>\n<td>0.1754057</td>\n<td>0.0003396</td>\n<td>0.9996534</td>\n<td>-99.6604405</td>\n<td>42.8076416</td>\n<td>0.3415722</td></tr>\n<tr><td>14</td>\n<td>0.8000005</td>\n<td>0.0011667</td>\n<td>0.0016270</td>\n<td>1.2497693</td>\n<td>0.0001997</td>\n<td>0.0012220</td>\n<td>0.1533753</td>\n<td>0.1536326</td>\n<td>0.0001627</td>\n<td>0.9998161</td>\n<td>-99.8372958</td>\n<td>24.9769277</td>\n<td>0.2277679</td></tr>\n<tr><td>15</td>\n<td>0.9000011</td>\n<td>0.0011193</td>\n<td>0.0015563</td>\n<td>1.1110783</td>\n<td>0.0001910</td>\n<td>0.0011458</td>\n<td>0.1363548</td>\n<td>0.1366895</td>\n<td>0.0001556</td>\n<td>0.9999717</td>\n<td>-99.8443699</td>\n<td>11.1078277</td>\n<td>0.1139555</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.0008655</td>\n<td>0.0002830</td>\n<td>1.0</td>\n<td>0.0000347</td>\n<td>0.0010901</td>\n<td>0.1227229</td>\n<td>0.1231297</td>\n<td>0.0000283</td>\n<td>1.0</td>\n<td>-99.9717031</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-9.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-9 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-9 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-9 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-9 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-9 .h2o-table th,\n#h2o-table-9 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-9 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-9\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>number_of_trees</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_auc</th>\n<th>training_pr_auc</th>\n<th>training_lift</th>\n<th>training_classification_error</th>\n<th>validation_rmse</th>\n<th>validation_logloss</th>\n<th>validation_auc</th>\n<th>validation_pr_auc</th>\n<th>validation_lift</th>\n<th>validation_classification_error</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2024-09-04 13:39:26</td>\n<td> 0.303 sec</td>\n<td>0.0</td>\n<td>0.3284021</td>\n<td>0.3727998</td>\n<td>0.5</td>\n<td>0.1229694</td>\n<td>1.0</td>\n<td>0.8770306</td>\n<td>0.3281190</td>\n<td>0.3723156</td>\n<td>0.5</td>\n<td>0.1227229</td>\n<td>1.0</td>\n<td>0.8772771</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:40:05</td>\n<td>40.102 sec</td>\n<td>5.0</td>\n<td>0.3050145</td>\n<td>0.3097362</td>\n<td>0.8732696</td>\n<td>0.4220105</td>\n<td>4.8592613</td>\n<td>0.1908721</td>\n<td>0.3051445</td>\n<td>0.3102077</td>\n<td>0.8701341</td>\n<td>0.4120955</td>\n<td>4.6857578</td>\n<td>0.1924691</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:40:43</td>\n<td> 1 min 17.748 sec</td>\n<td>10.0</td>\n<td>0.2956107</td>\n<td>0.2847490</td>\n<td>0.8750040</td>\n<td>0.4260373</td>\n<td>4.9163685</td>\n<td>0.1928882</td>\n<td>0.2961079</td>\n<td>0.2858775</td>\n<td>0.8715225</td>\n<td>0.4143665</td>\n<td>4.6850504</td>\n<td>0.1961136</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:41:19</td>\n<td> 1 min 54.142 sec</td>\n<td>15.0</td>\n<td>0.2913463</td>\n<td>0.2709008</td>\n<td>0.8765133</td>\n<td>0.4304983</td>\n<td>4.9550772</td>\n<td>0.1885927</td>\n<td>0.2921470</td>\n<td>0.2725545</td>\n<td>0.8726167</td>\n<td>0.4172444</td>\n<td>4.7310308</td>\n<td>0.1929266</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:41:59</td>\n<td> 2 min 33.389 sec</td>\n<td>20.0</td>\n<td>0.2893752</td>\n<td>0.2634940</td>\n<td>0.8776308</td>\n<td>0.4337969</td>\n<td>5.0108910</td>\n<td>0.1877893</td>\n<td>0.2905271</td>\n<td>0.2657793</td>\n<td>0.8730578</td>\n<td>0.4181833</td>\n<td>4.7699373</td>\n<td>0.1957959</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:42:34</td>\n<td> 3 min  8.663 sec</td>\n<td>25.0</td>\n<td>0.2879751</td>\n<td>0.2580700</td>\n<td>0.8794227</td>\n<td>0.4408007</td>\n<td>5.1377515</td>\n<td>0.1838509</td>\n<td>0.2893492</td>\n<td>0.2607815</td>\n<td>0.8744972</td>\n<td>0.4243018</td>\n<td>4.8633129</td>\n<td>0.1856410</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:43:12</td>\n<td> 3 min 46.355 sec</td>\n<td>30.0</td>\n<td>0.2870324</td>\n<td>0.2546098</td>\n<td>0.8811285</td>\n<td>0.4467608</td>\n<td>5.2279478</td>\n<td>0.1807300</td>\n<td>0.2887064</td>\n<td>0.2579098</td>\n<td>0.8755187</td>\n<td>0.4279481</td>\n<td>4.9177820</td>\n<td>0.1802211</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:43:48</td>\n<td> 4 min 22.443 sec</td>\n<td>35.0</td>\n<td>0.2861841</td>\n<td>0.2518981</td>\n<td>0.8827405</td>\n<td>0.4522110</td>\n<td>5.3146089</td>\n<td>0.1801100</td>\n<td>0.2880505</td>\n<td>0.2556373</td>\n<td>0.8767787</td>\n<td>0.4328304</td>\n<td>4.9920581</td>\n<td>0.1789588</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:44:22</td>\n<td> 4 min 56.367 sec</td>\n<td>40.0</td>\n<td>0.2855722</td>\n<td>0.2501352</td>\n<td>0.8840548</td>\n<td>0.4566459</td>\n<td>5.3812713</td>\n<td>0.1762161</td>\n<td>0.2876196</td>\n<td>0.2542531</td>\n<td>0.8777070</td>\n<td>0.4362445</td>\n<td>5.0564307</td>\n<td>0.1817820</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:44:50</td>\n<td> 5 min 24.470 sec</td>\n<td>45.0</td>\n<td>0.2854543</td>\n<td>0.2494945</td>\n<td>0.8842678</td>\n<td>0.4572559</td>\n<td>5.3882405</td>\n<td>0.1760745</td>\n<td>0.2875546</td>\n<td>0.2537607</td>\n<td>0.8778171</td>\n<td>0.4365577</td>\n<td>5.0574064</td>\n<td>0.1824627</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:45:11</td>\n<td> 5 min 45.752 sec</td>\n<td>50.0</td>\n<td>0.2853700</td>\n<td>0.2491979</td>\n<td>0.8844304</td>\n<td>0.4578054</td>\n<td>5.3971288</td>\n<td>0.1750266</td>\n<td>0.2875106</td>\n<td>0.2535521</td>\n<td>0.8779032</td>\n<td>0.4368459</td>\n<td>5.0500642</td>\n<td>0.1794719</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:45:34</td>\n<td> 6 min  8.853 sec</td>\n<td>55.0</td>\n<td>0.2851252</td>\n<td>0.2486742</td>\n<td>0.8849346</td>\n<td>0.4596377</td>\n<td>5.4217737</td>\n<td>0.1758877</td>\n<td>0.2873296</td>\n<td>0.2531580</td>\n<td>0.8782703</td>\n<td>0.4383435</td>\n<td>5.0939224</td>\n<td>0.1775906</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:45:46</td>\n<td> 6 min 21.210 sec</td>\n<td>60.0</td>\n<td>0.2851252</td>\n<td>0.2486742</td>\n<td>0.8849346</td>\n<td>0.4596377</td>\n<td>5.4217737</td>\n<td>0.1758877</td>\n<td>0.2873296</td>\n<td>0.2531580</td>\n<td>0.8782703</td>\n<td>0.4383435</td>\n<td>5.0939224</td>\n<td>0.1775906</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:45:59</td>\n<td> 6 min 33.696 sec</td>\n<td>65.0</td>\n<td>0.2851252</td>\n<td>0.2486742</td>\n<td>0.8849346</td>\n<td>0.4596377</td>\n<td>5.4217737</td>\n<td>0.1758877</td>\n<td>0.2873296</td>\n<td>0.2531580</td>\n<td>0.8782703</td>\n<td>0.4383435</td>\n<td>5.0939224</td>\n<td>0.1775906</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:46:11</td>\n<td> 6 min 45.923 sec</td>\n<td>70.0</td>\n<td>0.2851252</td>\n<td>0.2486742</td>\n<td>0.8849346</td>\n<td>0.4596377</td>\n<td>5.4217737</td>\n<td>0.1758877</td>\n<td>0.2873296</td>\n<td>0.2531580</td>\n<td>0.8782703</td>\n<td>0.4383435</td>\n<td>5.0939224</td>\n<td>0.1775906</td></tr>\n<tr><td></td>\n<td>2024-09-04 13:46:24</td>\n<td> 6 min 58.661 sec</td>\n<td>75.0</td>\n<td>0.2851252</td>\n<td>0.2486742</td>\n<td>0.8849346</td>\n<td>0.4596377</td>\n<td>5.4217737</td>\n<td>0.1758877</td>\n<td>0.2873296</td>\n<td>0.2531580</td>\n<td>0.8782703</td>\n<td>0.4383435</td>\n<td>5.0939224</td>\n<td>0.1775906</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-10.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-10 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-10 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-10 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-10 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-10 .h2o-table th,\n#h2o-table-10 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-10 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-10\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>Vehicle_Damage</td>\n<td>387860.1250000</td>\n<td>1.0</td>\n<td>0.4018488</td></tr>\n<tr><td>Previously_Insured</td>\n<td>150472.1406250</td>\n<td>0.3879547</td>\n<td>0.1558991</td></tr>\n<tr><td>Age</td>\n<td>145689.0625000</td>\n<td>0.3756227</td>\n<td>0.1509435</td></tr>\n<tr><td>Vintage</td>\n<td>91172.5390625</td>\n<td>0.2350655</td>\n<td>0.0944608</td></tr>\n<tr><td>Vehicle_Age</td>\n<td>71112.3984375</td>\n<td>0.1833455</td>\n<td>0.0736772</td></tr>\n<tr><td>Policy_Sales_Channel</td>\n<td>59822.2148438</td>\n<td>0.1542366</td>\n<td>0.0619798</td></tr>\n<tr><td>Region_Code</td>\n<td>29632.6171875</td>\n<td>0.0764003</td>\n<td>0.0307014</td></tr>\n<tr><td>Annual_Premium</td>\n<td>25456.4765625</td>\n<td>0.0656331</td>\n<td>0.0263746</td></tr>\n<tr><td>Gender</td>\n<td>3455.3181152</td>\n<td>0.0089087</td>\n<td>0.0035799</td></tr>\n<tr><td>Driving_License</td>\n<td>516.3658447</td>\n<td>0.0013313</td>\n<td>0.0005350</td></tr></tbody>\n  </table>\n</div>\n</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"},"metadata":{}}]},{"cell_type":"markdown","source":"* i used 1000 random seed for big data in training . \n\n42 = small data\n\n1000 = big data","metadata":{}},{"cell_type":"code","source":"%%time\n\n# View the AutoML Leaderboard\nlb = aml.leaderboard\nlb.head(rows=lb.nrows)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:47:55.332963Z","iopub.execute_input":"2024-09-04T13:47:55.333500Z","iopub.status.idle":"2024-09-04T13:47:55.358850Z","shell.execute_reply.started":"2024-09-04T13:47:55.333457Z","shell.execute_reply":"2024-09-04T13:47:55.357780Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"CPU times: user 3.32 ms, sys: 2.06 ms, total: 5.38 ms\nWall time: 8.59 ms\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"model_id                                 auc    logloss     aucpr    mean_per_class_error      rmse        mse\n----------------------------------  --------  ---------  --------  ----------------------  --------  ---------\nGBM_1_AutoML_1_20240904_133057      0.87827    0.253158  0.438343                0.234562  0.28733   0.0825583\nXGBoost_1_AutoML_1_20240904_133057  0.877858   0.252787  0.435414                0.229146  0.287399  0.0825982\nXGBoost_2_AutoML_1_20240904_133057  0.876286   0.254061  0.42965                 0.227508  0.288151  0.0830312\nGLM_1_AutoML_1_20240904_133057      0.841239   0.272436  0.329876                0.244493  0.298633  0.0891819\n[4 rows x 7 columns]\n","text/html":"<table class='dataframe'>\n<thead>\n<tr><th>model_id                          </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n</thead>\n<tbody>\n<tr><td>GBM_1_AutoML_1_20240904_133057    </td><td style=\"text-align: right;\">0.87827 </td><td style=\"text-align: right;\"> 0.253158</td><td style=\"text-align: right;\">0.438343</td><td style=\"text-align: right;\">              0.234562</td><td style=\"text-align: right;\">0.28733 </td><td style=\"text-align: right;\">0.0825583</td></tr>\n<tr><td>XGBoost_1_AutoML_1_20240904_133057</td><td style=\"text-align: right;\">0.877858</td><td style=\"text-align: right;\"> 0.252787</td><td style=\"text-align: right;\">0.435414</td><td style=\"text-align: right;\">              0.229146</td><td style=\"text-align: right;\">0.287399</td><td style=\"text-align: right;\">0.0825982</td></tr>\n<tr><td>XGBoost_2_AutoML_1_20240904_133057</td><td style=\"text-align: right;\">0.876286</td><td style=\"text-align: right;\"> 0.254061</td><td style=\"text-align: right;\">0.42965 </td><td style=\"text-align: right;\">              0.227508</td><td style=\"text-align: right;\">0.288151</td><td style=\"text-align: right;\">0.0830312</td></tr>\n<tr><td>GLM_1_AutoML_1_20240904_133057    </td><td style=\"text-align: right;\">0.841239</td><td style=\"text-align: right;\"> 0.272436</td><td style=\"text-align: right;\">0.329876</td><td style=\"text-align: right;\">              0.244493</td><td style=\"text-align: right;\">0.298633</td><td style=\"text-align: right;\">0.0891819</td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[4 rows x 7 columns]</pre>"},"metadata":{}}]},{"cell_type":"markdown","source":"* Metric roc-auc score is 0.87827 . The model making a good performance .","metadata":{}},{"cell_type":"code","source":"%%time\n\npreds = aml.predict(test)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:47:55.360252Z","iopub.execute_input":"2024-09-04T13:47:55.360791Z","iopub.status.idle":"2024-09-04T13:49:12.776298Z","shell.execute_reply.started":"2024-09-04T13:47:55.360748Z","shell.execute_reply":"2024-09-04T13:49:12.775264Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\nCPU times: user 297 ms, sys: 37.6 ms, total: 335 ms\nWall time: 1min 17s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\n# Extracting the probability for class 1 (positive response)\npreds_prob = preds['p1']","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:51:01.931589Z","iopub.execute_input":"2024-09-04T13:51:01.931971Z","iopub.status.idle":"2024-09-04T13:51:01.937584Z","shell.execute_reply.started":"2024-09-04T13:51:01.931930Z","shell.execute_reply":"2024-09-04T13:51:01.936649Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"CPU times: user 136 µs, sys: 20 µs, total: 156 µs\nWall time: 160 µs\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\n# Convert H2OFrame to pandas DataFrame\npreds_prob_df = preds_prob.as_data_frame()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:51:20.111659Z","iopub.execute_input":"2024-09-04T13:51:20.112407Z","iopub.status.idle":"2024-09-04T13:51:25.518026Z","shell.execute_reply.started":"2024-09-04T13:51:20.112366Z","shell.execute_reply":"2024-09-04T13:51:25.517138Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n\n  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 2.24 s, sys: 902 ms, total: 3.14 s\nWall time: 5.4 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\n# Load test data\ntest_df = h2o.as_list(test)  # Converts H2O test data to pandas DataFrame\nsubmission = pd.DataFrame()\nsubmission['id'] = test_df['id']  # Assuming 'id' column exists in test dataset\nsubmission['Response'] = preds_prob_df  # Adding the predicted probabilities","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:52:19.782513Z","iopub.execute_input":"2024-09-04T13:52:19.782900Z","iopub.status.idle":"2024-09-04T13:52:40.359024Z","shell.execute_reply.started":"2024-09-04T13:52:19.782862Z","shell.execute_reply":"2024-09-04T13:52:40.357944Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n\n  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 9.82 s, sys: 3.63 s, total: 13.4 s\nWall time: 20.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\n# Save the submission to a CSV file\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:52:49.870669Z","iopub.execute_input":"2024-09-04T13:52:49.871641Z","iopub.status.idle":"2024-09-04T13:53:10.690669Z","shell.execute_reply.started":"2024-09-04T13:52:49.871598Z","shell.execute_reply":"2024-09-04T13:53:10.689749Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"CPU times: user 20.6 s, sys: 227 ms, total: 20.8 s\nWall time: 20.8 s\n","output_type":"stream"}]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T13:53:21.384511Z","iopub.execute_input":"2024-09-04T13:53:21.385246Z","iopub.status.idle":"2024-09-04T13:53:21.394625Z","shell.execute_reply.started":"2024-09-04T13:53:21.385207Z","shell.execute_reply":"2024-09-04T13:53:21.393520Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"         id  Response\n0  11504798  0.017081\n1  11504799  0.424550\n2  11504800  0.245157\n3  11504801  0.001143\n4  11504802  0.029030","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11504798</td>\n      <td>0.017081</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11504799</td>\n      <td>0.424550</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11504800</td>\n      <td>0.245157</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11504801</td>\n      <td>0.001143</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11504802</td>\n      <td>0.029030</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#  Calculate the percentage of responses","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Convert the H2OFrame to a pandas DataFrame\npredictions_df = preds.as_data_frame()","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:00:20.995116Z","iopub.execute_input":"2024-09-04T14:00:20.995826Z","iopub.status.idle":"2024-09-04T14:00:32.176701Z","shell.execute_reply.started":"2024-09-04T14:00:20.995787Z","shell.execute_reply":"2024-09-04T14:00:32.175683Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n\n  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 4.81 s, sys: 1.91 s, total: 6.72 s\nWall time: 11.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\n# Convert probabilities to labels (0 or 1) based on a threshold of 0.5\npredictions_df['Label'] = predictions_df['p1'].apply(lambda x: 1 if x >= 0.5 else 0)","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:02:09.164188Z","iopub.execute_input":"2024-09-04T14:02:09.164564Z","iopub.status.idle":"2024-09-04T14:02:14.696834Z","shell.execute_reply.started":"2024-09-04T14:02:09.164530Z","shell.execute_reply":"2024-09-04T14:02:14.695907Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"CPU times: user 5.27 s, sys: 255 ms, total: 5.53 s\nWall time: 5.53 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\n# Count the number of each prediction (0: No Response, 1: Response)\nresponse_counts = predictions_df['Label'].value_counts()\n\n# Total number of predictions\ntotal = len(predictions_df)\n\ntotal","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:02:28.171297Z","iopub.execute_input":"2024-09-04T14:02:28.171681Z","iopub.status.idle":"2024-09-04T14:02:28.242465Z","shell.execute_reply.started":"2024-09-04T14:02:28.171645Z","shell.execute_reply":"2024-09-04T14:02:28.241336Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"CPU times: user 62.4 ms, sys: 20 µs, total: 62.4 ms\nWall time: 61.9 ms\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"7669866"},"metadata":{}}]},{"cell_type":"markdown","source":"* Model made predictions for 7,669,866 customers ","metadata":{}},{"cell_type":"code","source":"%%time\n\n# Respond\npercentage_respond = (response_counts[1] / total) * 100  # Percentage of '1' (Respond)\n\nprint(f\"Percentage of Customers Who Responded: {percentage_respond:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:02:32.323380Z","iopub.execute_input":"2024-09-04T14:02:32.324031Z","iopub.status.idle":"2024-09-04T14:02:32.329832Z","shell.execute_reply.started":"2024-09-04T14:02:32.323991Z","shell.execute_reply":"2024-09-04T14:02:32.328881Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Percentage of Customers Who Responded: 1.54%\nCPU times: user 277 µs, sys: 41 µs, total: 318 µs\nWall time: 319 µs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* Estimated 118,107 customers are predicted to accept the insurance offer ","metadata":{}},{"cell_type":"code","source":"%%time\n\n\n# Not Respond\n\npercentage_not_respond = (response_counts[0] / total) * 100  # Percentage of '0' (Not Respond)\n\nprint(f\"Percentage of Customers Who Did Not Respond: {percentage_not_respond:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-09-04T14:02:36.521956Z","iopub.execute_input":"2024-09-04T14:02:36.522431Z","iopub.status.idle":"2024-09-04T14:02:36.528155Z","shell.execute_reply.started":"2024-09-04T14:02:36.522392Z","shell.execute_reply":"2024-09-04T14:02:36.527226Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Percentage of Customers Who Did Not Respond: 98.46%\nCPU times: user 143 µs, sys: 0 ns, total: 143 µs\nWall time: 141 µs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* Estimated 7,551,759 customers are predicted to not accept the insurance offer ","metadata":{}}]}